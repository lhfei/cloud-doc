



```python
'''
Created on Jan 14, 2019

@author: Hefei Li
'''
import airflow
from airflow.models import DAG
from datetime import timedelta
from airflow.operators.hive_operator import HiveOperator
from airflow.operators.bash_operator import BashOperator

# default schema
default_schema = 'airflow'
default_hive_cli_conn_id='hive_cli_default'

args = {
    'owner': 'airflow',
    'start_date': airflow.utils.dates.days_ago(2),
    }

# Define the DAG
dag = DAG(
    dag_id = 'hive_simple_etl',
    default_args=args,
    schedule_interval="@daily",
    dagrun_timeout=timedelta(minutes=60),
    template_searchpath='/export/app_workspacees/flightdata',
    max_active_runs=10,
    )

init_tables = HiveOperator(
    task_id='init_tables',
    hql='scripts/create_tables.hql',
    schema=default_schema,
    hive_cli_conn_id=default_hive_cli_conn_id,
    hiveconf_jinja_translate=True,
    dag = dag,
    )

query_1_sum_all = HiveOperator(
    task_id='query_1_sum_all',
    hql='scripts/query_1_sum_all.hql',
    schema=default_schema,
    hive_cli_conn_id=default_hive_cli_conn_id,
    hiveconf_jinja_translate=True,
    dag = dag,
    )

put_data = BashOperator(
    task_id='put_data',
    bash_command='su - hdfs -c "hdfs dfs -rm -r -skipTrash /benchmark/airflow/lineitem/*; hdfs dfs -cp /benchmark/lineitem/lineitem.tbl.1.gz /benchmark/airflow/lineitem/"',  
    dag=dag,
    )

init_tables >> put_data

# put_data >> query_1_sum_all

if __name__ == "__main__":
    dag.cli()
```

