==================================================================================================================================
.CEPH DEPLOY SETUP
----------------------------------------------------------------------------------------------------------------------------------

 ADVANCED PACKAGE TOOL (APT)
 
	1 Add the release key:
		
		wget -q -O- 'https://ceph.com/git/?p=ceph.git;a=blob_plain;f=keys/release.asc' | sudo apt-key add -
	
	2 Add the Ceph packages to your repository(Replace {ceph-stable-release} with a stable Ceph release)
	
		#echo deb http://ceph.com/debian-{ceph-stable-release}/ $(lsb_release -sc) main | sudo tee /etc/apt/sources.list.d/ceph.list
		echo deb http://ceph.com/debian-giant/ $(lsb_release -sc) main | sudo tee /etc/apt/sources.list.d/ceph.list
	
	3 Update your repository and install ceph-deploy
	
		sudo apt-get update && sudo apt-get install ceph-deploy

==================================================================================================================================
 CEPH NODE SETUP
 
	1 INSTALL NTP
	
		sudo apt-get install ntp
		
	2 INSTALL SSH SERVER
	
		#Install an SSH server (if necessary) on each Ceph Node:
		
			sudo apt-get install openssh-server
			
		#Ensure the SSH server is running on ALL Ceph Nodes
	
	3 CREATE A CEPH USER
	
		#Create a user on each Ceph Node
			
			ssh user@ceph-server
			sudo useradd -d /home/{username} -m {username}
			sudo passwd {username}
			
			#sudo useradd -d /home/ceph -m ceph
			
		#For the user you added to each Ceph node, ensure that the user has sudo privileges
			
			echo "{username} ALL = (root) NOPASSWD:ALL" | sudo tee /etc/sudoers.d/{username}
			sudo chmod 0440 /etc/sudoers.d/{username}
			
			|~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
			| echo "ceph ALL = (root) NOPASSWD:ALL" | sudo tee /etc/sudoers.d/ceph 
			| sudo chmod 440 /etc/sudoers.d/ceph 
			|~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	3 ENABLE PASSWORD-LESS SSH
		
			#Generate the SSH keys, but do not use sudo or the root user. Leave the passphrase empty
				~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
				~ ssh-keygen
                ~ 
				~ Generating public/private key pair.
				~ Enter file in which to save the key (/ceph-admin/.ssh/id_rsa):
				~ Enter passphrase (empty for no passphrase):
				~ Enter same passphrase again:
				~ Your identification has been saved in /ceph-admin/.ssh/id_rsa.
				~ Your public key has been saved in /ceph-admin/.ssh/id_rsa.pub.
				~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

			#Copy the key to each Ceph Node, replacing {username} with the user name you created with Create a Ceph User			

				~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
				~ ssh-copy-id {username}@node1		ssh-copy-id ceph@114.80.177.125
				~ ssh-copy-id {username}@node2		ssh-copy-id ceph@114.80.177.126
				~ ssh-copy-id {username}@node3		ssh-copy-id ceph@114.80.177.127
				~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~			
			
			#(Recommended) Modify the ~/.ssh/config file of your ceph-deploy admin node 
			
				|~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
				| 
				| Host ubuntu124
				|	 Hostname ubuntu124
				|	 User ceph
				| Host 114.80.177.125
				|    Hostname ubuntu125
				|    User ceph
				| Host 114.80.177.126
				|   Hostname ubuntu126
				|    User ceph
				| Host 114.80.177.127
				|    Hostname ubuntu126
				|    User ceph
				|~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
				
				// login use ceph ,and modify /etc/hosts: 
					114.80.177.125 ubuntu125
					114.80.177.126 ubuntu126
					114.80.177.127 ubuntu127
				   
	4 ENABLE NETWORKING ON BOOTUP
	
	
	5 ENSURE CONNECTIVITY
	
	
	6 OPEN REQUIRED PORTS
	
	7 TTY
	
	8 SELINUX
	
	
----------------------------------------------------------------------------------------------------------------------------------	
		||	||	||		||	||	||		||	||	||		||	||	||		||	||	||		||	||	||		||	||	||		||	||	||
==================================================================================================================================
STORAGE CLUSTER QUICK START

.CREATE A CLUSTER
==================================================================================================================================
	ceph-deploy purgedata {ceph-node} [{ceph-node}]
	ceph-deploy forgetkeys
	ceph-deploy purge {ceph-node} [{ceph-node}]
	
	|~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	| ceph-deploy purgedata ubuntu124 ubuntu125 ubuntu126 ubuntu127
	| ceph-deploy forgetkeys
	| ceph-deploy purge ubuntu124 ubuntu125 ubuntu126 ubuntu127			//uninstall
	|~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	
	0 Create Admin node
	
		* sudo aptitude -y install ceph-deploy ceph-common ceph-mds

	
	1 Create the cluster
		
		ceph-deploy new {initial-monitor-node(s)}
		
		|~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
		| ceph-deploy new ubuntu125
		|~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
		* ceph-deploy new ubuntu125 ubuntu126 ubuntu127
		
	2 Change the default number of replicas in the Ceph configuration file from 3 to 2 
		#Add the following line under the [global] section in ceph.conf
		osd pool default size = 2
		
	3 If you have more than one network interface
	
	
	4 Install Ceph
		
		ceph-deploy install {ceph-node}[{ceph-node} ...]
		
		#eg: ceph-deploy install admin-node node1 node2 node3
		|~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
		| ceph-deploy install ubuntu124 ubuntu125 ubuntu126 ubuntu127
		|~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~	
		* ceph-deploy install ubuntu125 ubuntu126 ubuntu127
		
	
	5 Add the initial monitor(s) and gather the keys (new in ceph-deploy v1.1.3)
	
		ceph-deploy mon create-initial
		
		@deprecate -- just for earlier version ceph-deploy
		################################################################################
		#
		#ceph-deploy mon create {ceph-node}		|ceph-deploy mon destroy {ceph-node} 
		#|~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
		#| ceph-deploy mon create ubuntu125
		#|~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
		#	
		#ceph-deploy gatherkeys {ceph-node}
		#|~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
		#| ceph-deploy gatherkeys ubuntu125
		#|~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
		#
		################################################################################
	6 Add two OSDs
	
		|~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
		| ssh {node2}					--  ssh ubuntu126
		| sudo mkdir /var/local/osd0
		| exit
		|
		| ssh {node3}					--  ssh ubuntu127
		| sudo mkdir /var/local/osd1
		| exit
		|~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~	
		
		ceph-deploy osd prepare {ceph-node}:/path/to/directory
		ceph-deploy osd prepare {ceph-node}:/path/to/directory
		|~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
		| ceph-deploy osd prepare ubuntu126:/var/local/osd0 ubuntu127:/var/local/osd1
		|~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
		
		ceph-deploy osd activate {ceph-node}:/path/to/directory
		|~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
		| ceph-deploy osd activate ubuntu126:/var/local/osd0 ubuntu127:/var/local/osd1
		|~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

		
	7 Use ceph-deploy to copy the configuration file and admin key to your admin node and your Ceph Nodes so that you can use 
		the ceph CLI without having to specify the monitor address and ceph.client.admin.keyring each time you execute a command.
		
		ceph-deploy admin {admin-node} {ceph-node}
		|~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
		| ceph-deploy admin ubuntu124 ubuntu125 ubuntu126 ubuntu127
		|~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
		* ceph-deploy admin ubuntu124
		* ceph-deploy mds create ubuntu125
		
	8 Ensure that you have the correct permissions for the ceph.client.admin.keyring.
		
		sudo chmod +r /etc/ceph/ceph.client.admin.keyring
		|~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
		| sudo chmod +r /home/ceph/my-cluster/ceph.client.admin.keyring
		|~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	
	9 
		|~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
		| ceph mds stat
		| ceph health
		|~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
----------------------------------------------------------------------------------------------------------------------------------

==================================================================================================================================
OPERATING YOUR CLUSTER


----------------------------------------------------------------------------------------------------------------------------------

==================================================================================================================================

----------------------------------------------------------------------------------------------------------------------------------

==================================================================================================================================

----------------------------------------------------------------------------------------------------------------------------------

==================================================================================================================================

----------------------------------------------------------------------------------------------------------------------------------

==================================================================================================================================

----------------------------------------------------------------------------------------------------------------------------------


==================================================================================================================================